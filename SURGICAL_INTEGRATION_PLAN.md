# Plan Quir√∫rgico de Integraci√≥n: EfficientNet Deepfake Detector

**Objetivo:** Integrar detecci√≥n robusta de deepfakes usando EfficientNet del repositorio recomendado SIN afectar el funcionamiento actual del agente de voz y verificaci√≥n de identidad.

**Fecha:** 2025-11-03
**Estado:** ‚úÖ Listo para implementaci√≥n
**Prioridad:** üî¥ CR√çTICA

---

## üìä An√°lisis de Arquitectura Actual

### Flujo Actual de Verificaci√≥n

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (React)                              ‚îÇ
‚îÇ  AVSyncChallengeModal.tsx                                        ‚îÇ
‚îÇ  ‚Ä¢ Modo 1: Grabaci√≥n en vivo (webcam + mic)                     ‚îÇ
‚îÇ  ‚Ä¢ Modo 2: Carga de archivo manual                              ‚îÇ
‚îÇ  ‚Ä¢ Hook: useVideoCapture.ts                                     ‚îÇ
‚îÇ  ‚Ä¢ Service: avSyncService.ts                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ POST /api/avsync/score
                       ‚îÇ FormData: video + session_id + metadata
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 BACKEND API (Node.js + Express)                  ‚îÇ
‚îÇ  server/api/avsync.js                                            ‚îÇ
‚îÇ  ‚Ä¢ Multer: Recibe video y lo guarda en tmp/uploads/             ‚îÇ
‚îÇ  ‚Ä¢ Validaci√≥n: Tama√±o, tipo, consentimiento                     ‚îÇ
‚îÇ  ‚Ä¢ Forward: Env√≠a video_path al servicio Python                 ‚îÇ
‚îÇ  ‚Ä¢ Decision: Calcula ALLOW/NEXT/BLOCK/SUSPICIOUS_PERFECT        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ POST http://localhost:5000/score
                       ‚îÇ JSON: { video_path, session_id }
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              SERVICIO PYTHON (Flask + SyncNet)                   ‚îÇ
‚îÇ  syncnet-service/app.py                                          ‚îÇ
‚îÇ  ‚Ä¢ syncnet_wrapper.py: An√°lisis de sincronizaci√≥n labial        ‚îÇ
‚îÇ  ‚Ä¢ Retorna: score, offset_frames, confidence, min_dist          ‚îÇ
‚îÇ  ‚Ä¢ LIMITACI√ìN: Solo detecta mala sincronizaci√≥n labial          ‚îÇ
‚îÇ  ‚Ä¢ PROBLEMA: Deepfakes modernos pasan sin problema              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Puntos de Integraci√≥n Identificados

#### ‚úÖ **Sin Cambios Frontend**
- AVSyncChallengeModal.tsx ‚Üí **NO REQUIERE MODIFICACI√ìN**
- useVideoCapture.ts ‚Üí **NO REQUIERE MODIFICACI√ìN**
- avSyncService.ts ‚Üí **NO REQUIERE MODIFICACI√ìN**

**Raz√≥n:** El frontend solo env√≠a el video y recibe una respuesta. La mejora es transparente.

#### ‚ö†Ô∏è **Cambio M√≠nimo Backend**
- server/api/avsync.js ‚Üí **MODIFICACI√ìN MENOR**
  - Actualizar respuesta para incluir nuevos campos del ensemble
  - Mantener compatibilidad retroactiva con estructura actual

#### üîß **Integraci√≥n Principal en Servicio Python**
- syncnet-service/ ‚Üí **INTEGRACI√ìN QUIR√öRGICA**
  - Agregar m√≥dulos EfficientNet NUEVOS (no modificar existentes)
  - Actualizar app.py para usar ensemble
  - Mantener SyncNet funcionando exactamente igual

---

## üéØ Estrategia de Integraci√≥n: Patr√≥n Adaptador

### Principio: **Agregar, NO Reemplazar**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         CAPA DE ORQUESTACI√ìN (NUEVO)                             ‚îÇ
‚îÇ  ensemble_orchestrator.py                                        ‚îÇ
‚îÇ  ‚Ä¢ Coordina m√∫ltiples detectores                                 ‚îÇ
‚îÇ  ‚Ä¢ Combina resultados con pesos                                  ‚îÇ
‚îÇ  ‚Ä¢ Mantiene retrocompatibilidad                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                     ‚îÇ                      ‚îÇ
     ‚ñº                     ‚ñº                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SyncNet     ‚îÇ  ‚îÇ  EfficientNet    ‚îÇ  ‚îÇ  Blink Detector  ‚îÇ
‚îÇ  (Existente) ‚îÇ  ‚îÇ  (NUEVO)         ‚îÇ  ‚îÇ  (Fase 2)        ‚îÇ
‚îÇ              ‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ                  ‚îÇ
‚îÇ  ‚Ä¢ Wrapper   ‚îÇ  ‚îÇ  ‚Ä¢ Detector      ‚îÇ  ‚îÇ  ‚Ä¢ MediaPipe     ‚îÇ
‚îÇ    actual    ‚îÇ  ‚îÇ  ‚Ä¢ Frame Extract ‚îÇ  ‚îÇ  ‚Ä¢ Eye Analysis  ‚îÇ
‚îÇ  ‚Ä¢ SIN       ‚îÇ  ‚îÇ  ‚Ä¢ Pre-trained   ‚îÇ  ‚îÇ  ‚Ä¢ Pattern Check ‚îÇ
‚îÇ    CAMBIOS   ‚îÇ  ‚îÇ    Model         ‚îÇ  ‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Estructura de Archivos Propuesta

### Directorio `syncnet-service/` (NUEVO y EXISTENTE)

```
syncnet-service/
‚îú‚îÄ‚îÄ app.py                          [MODIFICAR MENOR]
‚îú‚îÄ‚îÄ syncnet_wrapper.py              [SIN CAMBIOS]
‚îú‚îÄ‚îÄ syncnet_python/                 [SIN CAMBIOS]
‚îÇ
‚îú‚îÄ‚îÄ ensemble/                       [üìÅ NUEVO DIRECTORIO]
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py            [üÜï Orquestador principal]
‚îÇ   ‚îú‚îÄ‚îÄ efficientnet_detector.py   [üÜï Detector EfficientNet]
‚îÇ   ‚îú‚îÄ‚îÄ frame_extractor.py         [üÜï Extracci√≥n de frames]
‚îÇ   ‚îî‚îÄ‚îÄ model_loader.py            [üÜï Carga de modelos]
‚îÇ
‚îú‚îÄ‚îÄ models/                         [EXPANDIR]
‚îÇ   ‚îú‚îÄ‚îÄ syncnet_v2.model           [Existente]
‚îÇ   ‚îú‚îÄ‚îÄ sfd_face.pth               [Existente]
‚îÇ   ‚îî‚îÄ‚îÄ efficientnet/              [üìÅ NUEVO]
‚îÇ       ‚îî‚îÄ‚îÄ best_model-v3.pt       [üÜï Modelo EfficientNet]
‚îÇ
‚îú‚îÄ‚îÄ utils/                          [üìÅ NUEVO DIRECTORIO]
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ video_utils.py             [üÜï Utilidades de video]
‚îÇ   ‚îî‚îÄ‚îÄ scoring.py                 [üÜï C√°lculo de scores]
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                [ACTUALIZAR]
‚îú‚îÄ‚îÄ .env                            [ACTUALIZAR]
‚îî‚îÄ‚îÄ tests/                          [üìÅ NUEVO]
    ‚îú‚îÄ‚îÄ test_ensemble.py           [üÜï Tests de integraci√≥n]
    ‚îî‚îÄ‚îÄ test_efficientnet.py       [üÜï Tests de EfficientNet]
```

---

## üîß Implementaci√≥n Paso a Paso

### FASE 1: Preparaci√≥n (D√≠a 1 - Sin Afectar Producci√≥n)

#### Paso 1.1: Clonar repositorio EfficientNet y extraer componentes

```bash
cd /tmp
git clone https://github.com/TRahulsingh/DeepfakeDetector.git
cd DeepfakeDetector

# Identificar archivos clave a portar
ls -la
cat web-app.py        # Ver funci√≥n predict_file()
cat classify.py       # Ver carga del modelo
cat requirements.txt  # Ver dependencias
```

**Archivos a portar:**
- L√≥gica de carga del modelo EfficientNet-B0
- Funci√≥n de predicci√≥n de im√°genes
- Preprocesamiento de im√°genes (resize, normalize)

#### Paso 1.2: Instalar dependencias NUEVAS

```bash
cd /workspaces/demovozv3/syncnet-service

# Backup del requirements.txt actual
cp requirements.txt requirements.txt.backup

# Agregar nuevas dependencias (sin eliminar existentes)
cat >> requirements.txt << 'EOF'

# --- EfficientNet Dependencies (Added 2025-11-03) ---
efficientnet-pytorch>=0.7.1
timm>=0.9.0                    # Alternativa m√°s moderna
Pillow>=10.0.0
scikit-learn>=1.3.0            # Para m√©tricas
gradio>=3.50.0                 # Para debugging (opcional)
EOF

# Instalar SOLO las nuevas dependencias
pip install efficientnet-pytorch timm Pillow scikit-learn
```

#### Paso 1.3: Descargar modelo pre-entrenado

```bash
cd /workspaces/demovozv3/syncnet-service
mkdir -p models/efficientnet
cd models/efficientnet

# Opci√≥n 1: Descargar desde el repositorio (si disponible)
wget https://github.com/TRahulsingh/DeepfakeDetector/releases/download/v1.0/best_model-v3.pt

# Opci√≥n 2: Usar modelo de Google Drive (si est√° compartido)
# gdown [GOOGLE_DRIVE_FILE_ID]

# Opci√≥n 3: Entrenar desde FaceForensics++ (m√°s lento)
# Ver: https://github.com/ondyari/FaceForensics

# Verificar descarga
ls -lh best_model-v3.pt
# Debe ser ~17-20 MB para EfficientNet-B0
```

#### Paso 1.4: Actualizar variables de entorno

```bash
cd /workspaces/demovozv3/syncnet-service

# Backup del .env actual
cp .env .env.backup

# Agregar configuraci√≥n de EfficientNet
cat >> .env << 'EOF'

# --- EfficientNet Configuration (Added 2025-11-03) ---
EFFICIENTNET_ENABLED=true
EFFICIENTNET_MODEL_PATH=./models/efficientnet/best_model-v3.pt
EFFICIENTNET_DEVICE=cpu                    # Cambiar a 'cuda' si hay GPU
EFFICIENTNET_MAX_FRAMES=20                 # Frames a analizar por video
EFFICIENTNET_BATCH_SIZE=8                  # Procesamiento por lote

# Ensemble Weights
ENSEMBLE_WEIGHT_SYNCNET=0.4
ENSEMBLE_WEIGHT_EFFICIENTNET=0.6
EOF
```

---

### FASE 2: Implementaci√≥n de M√≥dulos Nuevos (D√≠a 2-3)

#### Paso 2.1: Crear `ensemble/efficientnet_detector.py`

```python
"""
EfficientNet Deepfake Detector
Adaptado de: https://github.com/TRahulsingh/DeepfakeDetector
Integrado para trabajar con SyncNet en modo ensemble
"""

import torch
import torch.nn as nn
from efficientnet_pytorch import EfficientNet
from torchvision import transforms
from PIL import Image
import numpy as np
import logging
from pathlib import Path
from typing import Dict, List, Optional, Union

logger = logging.getLogger(__name__)


class EfficientNetDetector:
    """
    Deepfake detector using EfficientNet-B0

    Compatible con el repositorio TRahulsingh/DeepfakeDetector
    Adaptado para integraci√≥n con SyncNet
    """

    def __init__(
        self,
        model_path: str,
        device: str = 'cpu',
        confidence_threshold: float = 0.5
    ):
        """
        Initialize EfficientNet detector

        Args:
            model_path: Path to pre-trained model weights (.pt file)
            device: 'cuda' or 'cpu'
            confidence_threshold: Threshold for binary classification
        """
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.confidence_threshold = confidence_threshold

        logger.info(f"[EfficientNet] Initializing on device: {self.device}")

        # Build model architecture
        self.model = self._build_model()

        # Load pre-trained weights
        self._load_weights(model_path)

        # Set to evaluation mode
        self.model.to(self.device)
        self.model.eval()

        # Image preprocessing pipeline
        # Matches ImageNet normalization (used in pre-training)
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],  # ImageNet means
                std=[0.229, 0.224, 0.225]    # ImageNet stds
            )
        ])

        logger.info("[EfficientNet] Detector initialized successfully")

    def _build_model(self) -> nn.Module:
        """
        Build EfficientNet-B0 architecture with custom classifier

        Architecture matches TRahulsingh/DeepfakeDetector:
        - Base: EfficientNet-B0 (pretrained on ImageNet)
        - Classifier: Dropout(0.4) + Linear(num_features -> 2)
        - Output: 2 classes (Fake, Real)
        """
        # Load pre-trained EfficientNet-B0
        model = EfficientNet.from_pretrained('efficientnet-b0')

        # Replace final classifier for binary classification
        num_features = model._fc.in_features
        model._fc = nn.Sequential(
            nn.Dropout(p=0.4, inplace=True),
            nn.Linear(num_features, 2)  # Binary: [Fake, Real]
        )

        logger.info(f"[EfficientNet] Model architecture built (input features: {num_features})")
        return model

    def _load_weights(self, model_path: str):
        """Load pre-trained weights from file"""
        model_path = Path(model_path)

        if not model_path.exists():
            logger.warning(f"[EfficientNet] Model file not found: {model_path}")
            logger.warning("[EfficientNet] Using randomly initialized weights (NOT RECOMMENDED)")
            return

        try:
            # Load checkpoint
            checkpoint = torch.load(model_path, map_location=self.device)

            # Handle different checkpoint formats
            if isinstance(checkpoint, dict):
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint

            # Load state dict
            self.model.load_state_dict(state_dict, strict=False)
            logger.info(f"[EfficientNet] Loaded weights from {model_path}")

        except Exception as e:
            logger.error(f"[EfficientNet] Failed to load weights: {e}")
            raise RuntimeError(f"Failed to load model weights: {e}")

    def predict_image(self, image: Image.Image) -> Dict[str, Union[bool, float, dict]]:
        """
        Predict if a single image is real or fake

        Args:
            image: PIL Image (RGB)

        Returns:
            dict:
                is_real: bool - True if classified as Real
                confidence: float - Confidence in prediction (0-1)
                score: float - Score for "Real" class (0-1)
                raw_logits: list - Raw model outputs [fake_logit, real_logit]
                probabilities: dict - Softmax probabilities
        """
        with torch.no_grad():
            # Preprocess image
            img_tensor = self.transform(image).unsqueeze(0).to(self.device)

            # Forward pass
            outputs = self.model(img_tensor)

            # Apply softmax to get probabilities
            probabilities = torch.softmax(outputs, dim=1)

            # Extract class probabilities
            # outputs shape: [1, 2] where dim1 = [fake_prob, real_prob]
            fake_prob = probabilities[0][0].item()
            real_prob = probabilities[0][1].item()

            # Classification decision
            is_real = real_prob > self.confidence_threshold
            confidence = max(real_prob, fake_prob)

            return {
                'is_real': is_real,
                'confidence': confidence,
                'score': real_prob,  # Higher = more likely real
                'raw_logits': outputs[0].cpu().numpy().tolist(),
                'probabilities': {
                    'fake': fake_prob,
                    'real': real_prob
                }
            }

    def predict_frames(
        self,
        frames: List[Image.Image],
        aggregate_method: str = 'mean'
    ) -> Dict[str, Union[bool, float, dict, list]]:
        """
        Predict across multiple frames and aggregate results

        Args:
            frames: List of PIL Images
            aggregate_method: 'mean', 'median', 'max', 'voting'

        Returns:
            dict:
                is_real: bool - Aggregated classification
                score: float - Aggregated score (0-1)
                confidence: float - Average confidence
                consistency: float - Inter-frame consistency (1-std)
                num_frames: int
                frame_scores: list - Individual frame scores
                statistics: dict - Detailed statistics
        """
        if not frames:
            raise ValueError("No frames provided for prediction")

        logger.info(f"[EfficientNet] Analyzing {len(frames)} frames")

        predictions = []
        for idx, frame in enumerate(frames):
            try:
                pred = self.predict_image(frame)
                predictions.append(pred)
            except Exception as e:
                logger.error(f"[EfficientNet] Error processing frame {idx}: {e}")
                continue

        if not predictions:
            raise RuntimeError("Failed to process any frames")

        # Extract scores
        scores = np.array([p['score'] for p in predictions])
        confidences = np.array([p['confidence'] for p in predictions])

        # Aggregate scores
        if aggregate_method == 'mean':
            agg_score = float(np.mean(scores))
        elif aggregate_method == 'median':
            agg_score = float(np.median(scores))
        elif aggregate_method == 'max':
            agg_score = float(np.max(scores))
        elif aggregate_method == 'voting':
            # Majority vote on classifications
            votes = sum([1 if p['is_real'] else 0 for p in predictions])
            agg_score = votes / len(predictions)
        else:
            raise ValueError(f"Unknown aggregate method: {aggregate_method}")

        # Calculate consistency (lower std = more consistent)
        std_score = float(np.std(scores))
        consistency = 1.0 - min(std_score * 2, 1.0)  # Normalize to 0-1

        # Final classification
        is_real = agg_score > self.confidence_threshold
        avg_confidence = float(np.mean(confidences))

        return {
            'is_real': is_real,
            'score': agg_score,
            'confidence': avg_confidence,
            'consistency': consistency,
            'num_frames': len(frames),
            'frame_scores': scores.tolist(),
            'statistics': {
                'mean': float(np.mean(scores)),
                'median': float(np.median(scores)),
                'std': std_score,
                'min': float(np.min(scores)),
                'max': float(np.max(scores)),
                'q25': float(np.percentile(scores, 25)),
                'q75': float(np.percentile(scores, 75))
            },
            'aggregate_method': aggregate_method
        }

    def __repr__(self):
        return (
            f"EfficientNetDetector("
            f"device={self.device}, "
            f"threshold={self.confidence_threshold})"
        )
```

#### Paso 2.2: Crear `ensemble/frame_extractor.py`

```python
"""
Video Frame Extraction Utilities
Extrae frames de videos para an√°lisis con EfficientNet
"""

import cv2
import numpy as np
from PIL import Image
from pathlib import Path
from typing import List, Optional
import logging

logger = logging.getLogger(__name__)


class FrameExtractor:
    """
    Extract frames from video files

    Supports uniform sampling, random sampling, and key frame extraction
    """

    def __init__(
        self,
        max_frames: int = 20,
        sampling_method: str = 'uniform'
    ):
        """
        Initialize frame extractor

        Args:
            max_frames: Maximum number of frames to extract
            sampling_method: 'uniform', 'random', 'keyframes'
        """
        self.max_frames = max_frames
        self.sampling_method = sampling_method

        logger.info(
            f"[FrameExtractor] Initialized "
            f"(max_frames={max_frames}, method={sampling_method})"
        )

    def extract_frames(
        self,
        video_path: str,
        resize: Optional[tuple] = None
    ) -> List[Image.Image]:
        """
        Extract frames from video

        Args:
            video_path: Path to video file
            resize: Optional (width, height) to resize frames

        Returns:
            List of PIL Images (RGB)
        """
        video_path = Path(video_path)

        if not video_path.exists():
            raise FileNotFoundError(f"Video not found: {video_path}")

        # Open video
        cap = cv2.VideoCapture(str(video_path))

        if not cap.isOpened():
            raise RuntimeError(f"Failed to open video: {video_path}")

        # Get video properties
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        logger.info(
            f"[FrameExtractor] Video: {total_frames} frames @ {fps:.2f} FPS "
            f"({width}x{height})"
        )

        # Determine frame indices to extract
        if self.sampling_method == 'uniform':
            frame_indices = self._get_uniform_indices(total_frames)
        elif self.sampling_method == 'random':
            frame_indices = self._get_random_indices(total_frames)
        elif self.sampling_method == 'keyframes':
            frame_indices = self._get_keyframe_indices(cap, total_frames)
        else:
            raise ValueError(f"Unknown sampling method: {self.sampling_method}")

        # Extract frames
        frames = []
        current_frame = 0

        while cap.isOpened() and len(frames) < self.max_frames:
            ret, frame = cap.read()

            if not ret:
                break

            if current_frame in frame_indices:
                # Convert BGR to RGB
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                # Convert to PIL Image
                pil_image = Image.fromarray(frame_rgb)

                # Optional resize
                if resize:
                    pil_image = pil_image.resize(resize, Image.BICUBIC)

                frames.append(pil_image)

            current_frame += 1

        cap.release()

        logger.info(f"[FrameExtractor] Extracted {len(frames)} frames")

        if not frames:
            raise RuntimeError("No frames extracted from video")

        return frames

    def _get_uniform_indices(self, total_frames: int) -> List[int]:
        """Get uniformly distributed frame indices"""
        if self.max_frames >= total_frames:
            return list(range(total_frames))

        # Uniform spacing
        step = total_frames / self.max_frames
        indices = [int(i * step) for i in range(self.max_frames)]

        return indices

    def _get_random_indices(self, total_frames: int) -> List[int]:
        """Get random frame indices"""
        if self.max_frames >= total_frames:
            return list(range(total_frames))

        indices = np.random.choice(
            total_frames,
            size=self.max_frames,
            replace=False
        )

        return sorted(indices.tolist())

    def _get_keyframe_indices(
        self,
        cap: cv2.VideoCapture,
        total_frames: int
    ) -> List[int]:
        """
        Get key frame indices (scene changes, high motion)

        Simplified implementation using frame difference
        """
        # For now, fallback to uniform sampling
        # TODO: Implement proper keyframe detection using scene change detection
        logger.warning(
            "[FrameExtractor] Keyframe detection not implemented, "
            "using uniform sampling"
        )
        return self._get_uniform_indices(total_frames)
```

#### Paso 2.3: Crear `ensemble/orchestrator.py` (Coraz√≥n de la integraci√≥n)

```python
"""
Ensemble Orchestrator
Coordina m√∫ltiples detectores (SyncNet + EfficientNet + futuros)
Combina resultados con pesos configurables
Mantiene retrocompatibilidad con API existente
"""

import time
import logging
from typing import Dict, Optional, Union
from pathlib import Path

# Importar detectores
try:
    from syncnet_wrapper import SyncNetWrapper
    SYNCNET_AVAILABLE = True
except ImportError:
    SYNCNET_AVAILABLE = False
    logging.warning("[Orchestrator] SyncNet not available")

try:
    from ensemble.efficientnet_detector import EfficientNetDetector
    from ensemble.frame_extractor import FrameExtractor
    EFFICIENTNET_AVAILABLE = True
except ImportError:
    EFFICIENTNET_AVAILABLE = False
    logging.warning("[Orchestrator] EfficientNet not available")

logger = logging.getLogger(__name__)


class EnsembleOrchestrator:
    """
    Orquesta m√∫ltiples detectores de deepfakes

    Caracter√≠sticas:
    - Combina SyncNet (existente) + EfficientNet (nuevo)
    - Pesos configurables
    - Retrocompatible con API actual
    - Extensible para futuros detectores
    """

    def __init__(
        self,
        syncnet_wrapper: Optional[SyncNetWrapper] = None,
        efficientnet_detector: Optional[EfficientNetDetector] = None,
        weights: Optional[Dict[str, float]] = None
    ):
        """
        Initialize ensemble orchestrator

        Args:
            syncnet_wrapper: Instance of SyncNetWrapper (opcional)
            efficientnet_detector: Instance of EfficientNetDetector (opcional)
            weights: Dict con pesos {'syncnet': 0.4, 'efficientnet': 0.6}
        """
        self.syncnet = syncnet_wrapper
        self.efficientnet = efficientnet_detector

        # Default weights (ajustados seg√∫n investigaci√≥n)
        self.weights = weights or {
            'syncnet': 0.4,       # Menor peso (vulnerable a deepfakes)
            'efficientnet': 0.6,  # Mayor peso (detecta artefactos faciales)
        }

        # Validate weights sum to 1.0
        total_weight = sum(self.weights.values())
        if not (0.99 <= total_weight <= 1.01):
            logger.warning(
                f"[Orchestrator] Weights sum to {total_weight}, normalizing..."
            )
            # Normalize
            self.weights = {k: v/total_weight for k, v in self.weights.items()}

        logger.info(f"[Orchestrator] Initialized with weights: {self.weights}")
        logger.info(f"[Orchestrator] SyncNet: {'‚úì' if self.syncnet else '‚úó'}")
        logger.info(f"[Orchestrator] EfficientNet: {'‚úì' if self.efficientnet else '‚úó'}")

    def analyze_video(
        self,
        video_path: str,
        session_id: str
    ) -> Dict[str, Union[float, str, dict, bool]]:
        """
        Analiza video usando ensemble de detectores

        Args:
            video_path: Path to video file
            session_id: Session identifier

        Returns:
            dict con estructura COMPATIBLE con API actual + nuevos campos
        """
        start_time = time.time()

        logger.info(f"[Orchestrator] Analyzing video: {video_path} (session: {session_id})")

        # Resultados individuales
        results = {}
        errors = {}

        # 1. Run SyncNet (si disponible)
        if self.syncnet:
            try:
                syncnet_result = self.syncnet.process_video(video_path, session_id)
                results['syncnet'] = syncnet_result
                logger.info(f"[Orchestrator] SyncNet score: {syncnet_result.get('score', 'N/A')}")
            except Exception as e:
                logger.error(f"[Orchestrator] SyncNet failed: {e}")
                errors['syncnet'] = str(e)

        # 2. Run EfficientNet (si disponible)
        if self.efficientnet:
            try:
                # Extract frames
                extractor = FrameExtractor(max_frames=20, sampling_method='uniform')
                frames = extractor.extract_frames(video_path)

                # Run detector
                efficientnet_result = self.efficientnet.predict_frames(
                    frames,
                    aggregate_method='mean'
                )
                results['efficientnet'] = efficientnet_result
                logger.info(f"[Orchestrator] EfficientNet score: {efficientnet_result.get('score', 'N/A')}")
            except Exception as e:
                logger.error(f"[Orchestrator] EfficientNet failed: {e}")
                errors['efficientnet'] = str(e)

        # 3. Calcular ensemble score
        ensemble_result = self._calculate_ensemble(results, errors)

        # 4. Agregar metadata
        processing_time_ms = int((time.time() - start_time) * 1000)
        ensemble_result['processing_time_ms'] = processing_time_ms
        ensemble_result['session_id'] = session_id

        logger.info(
            f"[Orchestrator] Final score: {ensemble_result['combined_score']:.3f} "
            f"(decision: {ensemble_result['decision']}, time: {processing_time_ms}ms)"
        )

        return ensemble_result

    def _calculate_ensemble(
        self,
        results: Dict[str, dict],
        errors: Dict[str, str]
    ) -> Dict[str, Union[float, str, dict, bool]]:
        """
        Combina resultados de m√∫ltiples detectores

        Estrategia:
        - Si AMBOS disponibles: weighted average
        - Si SOLO UNO disponible: usar ese resultado
        - Si NINGUNO disponible: error
        """
        # Check si tenemos al menos un resultado
        if not results:
            raise RuntimeError(
                f"All detectors failed. Errors: {errors}"
            )

        # Caso 1: Ambos detectores funcionaron
        if 'syncnet' in results and 'efficientnet' in results:
            syncnet_score = results['syncnet']['score']
            efficientnet_score = results['efficientnet']['score']

            # Weighted average
            combined_score = (
                self.weights['syncnet'] * syncnet_score +
                self.weights['efficientnet'] * efficientnet_score
            )

            # Decision basado en score combinado
            decision = self._make_decision(combined_score, results)

            return {
                'combined_score': round(combined_score, 4),
                'score': round(combined_score, 4),  # Retrocompatibilidad
                'decision': decision,
                'is_likely_real': combined_score > 0.6,
                'confidence': self._calculate_confidence(results),

                # Detalles individuales
                'detectors': {
                    'syncnet': {
                        'score': round(syncnet_score, 4),
                        'offset_frames': results['syncnet'].get('offset_frames'),
                        'confidence': results['syncnet'].get('confidence'),
                        'min_dist': results['syncnet'].get('min_dist'),
                        'lag_ms': results['syncnet'].get('lag_ms'),
                    },
                    'efficientnet': {
                        'score': round(efficientnet_score, 4),
                        'confidence': results['efficientnet'].get('confidence'),
                        'consistency': results['efficientnet'].get('consistency'),
                        'num_frames': results['efficientnet'].get('num_frames'),
                    }
                },

                # Weights usados
                'weights': self.weights,

                # Retrocompatibilidad con campos de SyncNet
                'offset_frames': results['syncnet'].get('offset_frames', 0),
                'min_dist': results['syncnet'].get('min_dist', 0),
                'lag_ms': results['syncnet'].get('lag_ms', 0),

                # Metadata
                'ensemble_mode': 'full',
                'detectors_used': ['syncnet', 'efficientnet'],
                'errors': errors if errors else None
            }

        # Caso 2: Solo SyncNet disponible
        elif 'syncnet' in results:
            logger.warning("[Orchestrator] Only SyncNet available, using fallback mode")
            syncnet_result = results['syncnet']

            return {
                'combined_score': syncnet_result['score'],
                'score': syncnet_result['score'],
                'decision': self._make_decision(syncnet_result['score'], results),
                'is_likely_real': syncnet_result['score'] > 0.6,
                'confidence': syncnet_result.get('confidence', 0),

                # Detalle
                'detectors': {
                    'syncnet': syncnet_result
                },

                # Retrocompatibilidad
                'offset_frames': syncnet_result.get('offset_frames', 0),
                'min_dist': syncnet_result.get('min_dist', 0),
                'lag_ms': syncnet_result.get('lag_ms', 0),

                # Metadata
                'ensemble_mode': 'syncnet_only',
                'detectors_used': ['syncnet'],
                'errors': errors
            }

        # Caso 3: Solo EfficientNet disponible
        elif 'efficientnet' in results:
            logger.warning("[Orchestrator] Only EfficientNet available, using fallback mode")
            efficientnet_result = results['efficientnet']

            return {
                'combined_score': efficientnet_result['score'],
                'score': efficientnet_result['score'],
                'decision': self._make_decision(efficientnet_result['score'], results),
                'is_likely_real': efficientnet_result['score'] > 0.6,
                'confidence': efficientnet_result.get('confidence', 0),

                # Detalle
                'detectors': {
                    'efficientnet': efficientnet_result
                },

                # Retrocompatibilidad (valores default)
                'offset_frames': 0,
                'min_dist': 0,
                'lag_ms': 0,

                # Metadata
                'ensemble_mode': 'efficientnet_only',
                'detectors_used': ['efficientnet'],
                'errors': errors
            }

        else:
            raise RuntimeError("No detector results available")

    def _make_decision(
        self,
        combined_score: float,
        results: Dict[str, dict]
    ) -> str:
        """
        Toma decisi√≥n basada en score combinado

        Compatiblecon las decisiones actuales:
        - ALLOW: ‚â•80% (alta confianza)
        - NEXT: 60-79% o 40-59% (media/baja confianza)
        - BLOCK: <40% (riesgo alto)
        - SUSPICIOUS_PERFECT: M√©tricas sospechosamente perfectas
        """
        # Check for suspiciously perfect metrics (deepfake moderno)
        if self._is_suspiciously_perfect(results):
            logger.warning("[Orchestrator] Suspiciously perfect metrics detected!")
            return 'SUSPICIOUS_PERFECT'

        # Score-based decision
        if combined_score >= 0.80:
            return 'ALLOW'
        elif combined_score >= 0.40:
            return 'NEXT'
        else:
            return 'BLOCK'

    def _is_suspiciously_perfect(self, results: Dict[str, dict]) -> bool:
        """
        Detecta m√©tricas sospechosamente perfectas

        Los deepfakes modernos pueden tener:
        - Score muy alto (>95%)
        - Offset = 0 frames (perfecta sincronizaci√≥n)
        - Confidence muy alta (>10)
        - Min dist muy baja (<6)

        Esto NO es normal en videos humanos reales
        """
        if 'syncnet' not in results:
            return False

        syncnet = results['syncnet']

        is_perfect = (
            syncnet.get('score', 0) >= 0.95 and
            abs(syncnet.get('offset_frames', 1)) == 0 and
            syncnet.get('confidence', 0) > 10.0 and
            syncnet.get('min_dist', 10) < 6.0
        )

        return is_perfect

    def _calculate_confidence(self, results: Dict[str, dict]) -> float:
        """
        Calcula confianza global del ensemble

        Basado en:
        - Confianzas individuales
        - Consistencia entre detectores
        """
        confidences = []

        if 'syncnet' in results:
            confidences.append(results['syncnet'].get('confidence', 0) / 10.0)  # Normalize

        if 'efficientnet' in results:
            confidences.append(results['efficientnet'].get('confidence', 0))

        if not confidences:
            return 0.0

        # Average confidence
        avg_confidence = sum(confidences) / len(confidences)

        # Clip to 0-1 range
        return max(0.0, min(1.0, avg_confidence))
```

---

### FASE 3: Integraci√≥n con Flask App (D√≠a 4)

#### Paso 3.1: Actualizar `app.py` (M√çNIMAS MODIFICACIONES)

```python
"""
Flask server for AV-Sync analysis using Ensemble (SyncNet + EfficientNet)
MODIFICADO: 2025-11-03 - Integraci√≥n de EfficientNet Detector
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import logging
import time
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# [NUEVO] Import Ensemble Orchestrator
try:
    from ensemble.orchestrator import EnsembleOrchestrator
    from ensemble.efficientnet_detector import EfficientNetDetector
    ENSEMBLE_AVAILABLE = True
except ImportError:
    ENSEMBLE_AVAILABLE = False
    logging.warning("Ensemble not available - running in legacy mode")

# [EXISTENTE] Import SyncNet wrapper
try:
    from syncnet_wrapper import SyncNetWrapper
    SYNCNET_AVAILABLE = True
except ImportError:
    SYNCNET_AVAILABLE = False
    logging.warning("SyncNet wrapper not available - running in demo mode")

# Initialize Flask app
app = Flask(__name__)
CORS(app)

# Configure logging
log_level = os.getenv('LOG_LEVEL', 'INFO')
logging.basicConfig(
    level=getattr(logging, log_level),
    format='[%(asctime)s] %(levelname)s in %(module)s: %(message)s'
)
logger = logging.getLogger(__name__)

# Get absolute paths
BASE_DIR = Path(__file__).parent.absolute()

# [ACTUALIZADO] Configuration
CONFIG = {
    # SyncNet (existente)
    'model_path': os.getenv('MODEL_PATH', str(BASE_DIR / 'models' / 'syncnet_v2.model')),
    'detector_path': os.getenv('DETECTOR_PATH', str(BASE_DIR / 'models' / 'sfd_face.pth')),
    'tmp_dir': os.getenv('TMP_DIR', str(BASE_DIR / 'tmp')),
    'upload_dir': os.getenv('UPLOAD_DIR', str(BASE_DIR / 'tmp' / 'uploads')),
    'max_video_size_mb': int(os.getenv('MAX_VIDEO_SIZE_MB', '10')),
    'processing_timeout': int(os.getenv('PROCESSING_TIMEOUT_SECONDS', '30')),

    # [NUEVO] EfficientNet configuration
    'efficientnet_enabled': os.getenv('EFFICIENTNET_ENABLED', 'true').lower() == 'true',
    'efficientnet_model_path': os.getenv(
        'EFFICIENTNET_MODEL_PATH',
        str(BASE_DIR / 'models' / 'efficientnet' / 'best_model-v3.pt')
    ),
    'efficientnet_device': os.getenv('EFFICIENTNET_DEVICE', 'cpu'),
    'efficientnet_max_frames': int(os.getenv('EFFICIENTNET_MAX_FRAMES', '20')),

    # [NUEVO] Ensemble weights
    'ensemble_weight_syncnet': float(os.getenv('ENSEMBLE_WEIGHT_SYNCNET', '0.4')),
    'ensemble_weight_efficientnet': float(os.getenv('ENSEMBLE_WEIGHT_EFFICIENTNET', '0.6')),
}

# [NUEVO] Initialize Ensemble Orchestrator (lazy loading)
ensemble_orchestrator = None

def get_ensemble():
    """Lazy initialization of Ensemble Orchestrator"""
    global ensemble_orchestrator

    if ensemble_orchestrator is None:
        try:
            logger.info("[App] Initializing Ensemble Orchestrator...")

            # Initialize SyncNet
            syncnet = None
            if SYNCNET_AVAILABLE:
                syncnet = SyncNetWrapper(
                    model_path=CONFIG['model_path'],
                    detector_path=CONFIG['detector_path'],
                    tmp_dir=CONFIG['tmp_dir']
                )
                logger.info("[App] SyncNet initialized ‚úì")

            # Initialize EfficientNet (if enabled)
            efficientnet = None
            if CONFIG['efficientnet_enabled'] and ENSEMBLE_AVAILABLE:
                efficientnet = EfficientNetDetector(
                    model_path=CONFIG['efficientnet_model_path'],
                    device=CONFIG['efficientnet_device']
                )
                logger.info("[App] EfficientNet initialized ‚úì")

            # Create orchestrator
            ensemble_orchestrator = EnsembleOrchestrator(
                syncnet_wrapper=syncnet,
                efficientnet_detector=efficientnet,
                weights={
                    'syncnet': CONFIG['ensemble_weight_syncnet'],
                    'efficientnet': CONFIG['ensemble_weight_efficientnet']
                }
            )

            logger.info("[App] Ensemble Orchestrator initialized successfully")

        except Exception as e:
            logger.error(f"[App] Failed to initialize Ensemble: {str(e)}")
            return None

    return ensemble_orchestrator


@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    ensemble = get_ensemble()

    return jsonify({
        'status': 'healthy',
        'service': 'deepfake-detection-ensemble',
        'version': '2.0.0',  # [ACTUALIZADO] Versi√≥n
        'detectors': {
            'syncnet': SYNCNET_AVAILABLE,
            'efficientnet': CONFIG['efficientnet_enabled'] and ENSEMBLE_AVAILABLE,
        },
        'ensemble_available': ensemble is not None,
        'config': {
            'max_video_size_mb': CONFIG['max_video_size_mb'],
            'processing_timeout': CONFIG['processing_timeout'],
            'efficientnet_max_frames': CONFIG['efficientnet_max_frames'],
        }
    })


@app.route('/score', methods=['POST'])
def score_video():
    """
    Analyze video using Ensemble (SyncNet + EfficientNet)

    [MODIFICADO] Ahora usa EnsembleOrchestrator en lugar de solo SyncNet
    [COMPATIBLE] Mantiene la misma API request/response
    """
    start_time = time.time()

    try:
        # Parse request
        data = request.get_json()

        if not data:
            return jsonify({'error': 'Request body must be JSON'}), 400

        video_path = data.get('video_path')
        session_id = data.get('session_id', 'unknown')

        # Validate
        if not video_path:
            return jsonify({'error': 'video_path is required'}), 400

        if not os.path.exists(video_path):
            return jsonify({'error': f'Video file not found: {video_path}'}), 404

        # Check file size
        file_size_mb = os.path.getsize(video_path) / (1024 * 1024)
        if file_size_mb > CONFIG['max_video_size_mb']:
            return jsonify({
                'error': f'Video file too large: {file_size_mb:.2f} MB (max: {CONFIG["max_video_size_mb"]} MB)'
            }), 400

        logger.info(f'[{session_id}] Processing video: {video_path} ({file_size_mb:.2f} MB)')

        # [MODIFICADO] Get Ensemble Orchestrator
        ensemble = get_ensemble()

        if ensemble is None:
            # [FALLBACK] Demo mode
            logger.warning(f'[{session_id}] Ensemble not available - returning demo data')
            return jsonify({
                'offset_frames': 2,
                'confidence': 9.5,
                'min_dist': 5.8,
                'score': 0.88,
                'combined_score': 0.88,
                'lag_ms': 80.0,
                'decision': 'ALLOW',
                'processing_time_ms': 1000,
                'demo_mode': True,
                'debug': {
                    'message': 'Ensemble not initialized - demo mode active'
                }
            })

        # [NUEVO] Process video with Ensemble
        try:
            result = ensemble.analyze_video(video_path, session_id)

            processing_time_ms = int((time.time() - start_time) * 1000)
            result['processing_time_ms'] = processing_time_ms

            logger.info(
                f'[{session_id}] Result: score={result["combined_score"]:.3f}, '
                f'decision={result["decision"]}, time={processing_time_ms}ms'
            )

            return jsonify(result)

        except TimeoutError:
            logger.error(f'[{session_id}] Processing timeout')
            return jsonify({
                'error': 'Processing timeout',
                'message': f'Video processing exceeded {CONFIG["processing_timeout"]}s limit'
            }), 408

    except Exception as e:
        logger.error(f'Error processing video: {str(e)}', exc_info=True)
        return jsonify({
            'error': 'Internal server error',
            'message': str(e),
            'type': type(e).__name__
        }), 500


@app.route('/test', methods=['GET'])
def test():
    """Test endpoint"""
    return jsonify({
        'message': 'Ensemble Deepfake Detection Service',
        'timestamp': time.time(),
        'config': CONFIG
    })


@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Endpoint not found'}), 404


@app.errorhandler(500)
def internal_error(error):
    logger.error(f'Internal server error: {str(error)}')
    return jsonify({'error': 'Internal server error'}), 500


if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'

    logger.info(f"Starting Ensemble Deepfake Detection Service on port {port}")
    logger.info(f"Debug mode: {debug}")
    logger.info(f"SyncNet model: {CONFIG['model_path']}")
    logger.info(f"EfficientNet model: {CONFIG['efficientnet_model_path']}")
    logger.info(f"EfficientNet enabled: {CONFIG['efficientnet_enabled']}")
    logger.info(f"Temp directory: {CONFIG['tmp_dir']}")

    # Ensure directories exist
    Path(CONFIG['tmp_dir']).mkdir(parents=True, exist_ok=True)
    Path(CONFIG['upload_dir']).mkdir(parents=True, exist_ok=True)

    app.run(host='0.0.0.0', port=port, debug=debug)
```

---

### FASE 4: Testing y Validaci√≥n (D√≠a 5)

#### Paso 4.1: Crear tests

```bash
cd /workspaces/demovozv3/syncnet-service

# Crear directorio de tests
mkdir -p tests

# Test de EfficientNet standalone
cat > tests/test_efficientnet.py << 'EOF'
import pytest
from PIL import Image
import numpy as np
from ensemble.efficientnet_detector import EfficientNetDetector

def test_efficientnet_initialization():
    detector = EfficientNetDetector(
        model_path='./models/efficientnet/best_model-v3.pt',
        device='cpu'
    )
    assert detector is not None

def test_efficientnet_predict_image():
    detector = EfficientNetDetector(
        model_path='./models/efficientnet/best_model-v3.pt'
    )

    # Create dummy image
    img = Image.new('RGB', (224, 224), color='red')

    result = detector.predict_image(img)

    assert 'score' in result
    assert 0 <= result['score'] <= 1
    assert 'confidence' in result
    assert 'probabilities' in result
EOF

# Test de Ensemble
cat > tests/test_ensemble.py << 'EOF'
import pytest
from ensemble.orchestrator import EnsembleOrchestrator
from syncnet_wrapper import SyncNetWrapper
from ensemble.efficientnet_detector import EfficientNetDetector

def test_ensemble_initialization():
    syncnet = SyncNetWrapper(
        model_path='./models/syncnet_v2.model',
        detector_path='./models/sfd_face.pth',
        tmp_dir='./tmp'
    )

    efficientnet = EfficientNetDetector(
        model_path='./models/efficientnet/best_model-v3.pt'
    )

    orchestrator = EnsembleOrchestrator(
        syncnet_wrapper=syncnet,
        efficientnet_detector=efficientnet
    )

    assert orchestrator is not None
    assert orchestrator.weights['syncnet'] == 0.4
    assert orchestrator.weights['efficientnet'] == 0.6
EOF

# Correr tests
pytest tests/ -v
```

#### Paso 4.2: Test manual end-to-end

```bash
# Terminal 1: Iniciar servicio Python
cd /workspaces/demovozv3/syncnet-service
python3 app.py

# Terminal 2: Test de health check
curl http://localhost:5000/health | jq

# Terminal 3: Test con video real
cd /workspaces/demovozv3
curl -X POST http://localhost:5000/score \
  -H "Content-Type: application/json" \
  -d '{
    "video_path": "/path/to/test/video.webm",
    "session_id": "test_001"
  }' | jq
```

---

### FASE 5: Deployment (D√≠a 6)

#### Paso 5.1: Actualizar scripts de deployment

```bash
# Actualizar render.yaml
cat >> /workspaces/demovozv3/render.yaml << 'EOF'

  # SyncNet Service (Updated with EfficientNet)
  - type: web
    name: syncnet-ensemble-service
    env: python
    plan: standard  # Upgraded from free (necesita m√°s RAM)
    buildCommand: |
      cd syncnet-service
      pip install -r requirements.txt
      ./setup.sh
      # Download EfficientNet model
      mkdir -p models/efficientnet
      wget -O models/efficientnet/best_model-v3.pt https://[URL_DEL_MODELO]
    startCommand: cd syncnet-service && gunicorn app:app -c gunicorn_config.py
    envVars:
      - key: EFFICIENTNET_ENABLED
        value: true
      - key: EFFICIENTNET_MODEL_PATH
        value: ./models/efficientnet/best_model-v3.pt
      - key: EFFICIENTNET_DEVICE
        value: cpu
      - key: ENSEMBLE_WEIGHT_SYNCNET
        value: 0.4
      - key: ENSEMBLE_WEIGHT_EFFICIENTNET
        value: 0.6
EOF
```

---

## üìä Validaci√≥n de Compatibilidad

### Respuesta API Antes (Solo SyncNet)

```json
{
  "offset_frames": 0,
  "confidence": 4.638,
  "min_dist": 6.627,
  "score": 0.846,
  "lag_ms": 0.0,
  "processing_time_ms": 7234,
  "decision": "ALLOW",
  "reason_codes": ["HIGH_SYNC_SCORE", ...],
  "session_id": "sess_xyz",
  "ttl_ms": 1730678400000
}
```

### Respuesta API Despu√©s (Ensemble) - COMPATIBLE

```json
{
  // [COMPATIBLE] Campos existentes mantenidos
  "offset_frames": 0,
  "confidence": 0.85,
  "min_dist": 6.627,
  "score": 0.75,              // AHORA es combined_score
  "lag_ms": 0.0,
  "processing_time_ms": 12450,
  "decision": "ALLOW",
  "session_id": "sess_xyz",
  "ttl_ms": 1730678400000,

  // [NUEVO] Campos adicionales del ensemble
  "combined_score": 0.75,
  "is_likely_real": true,
  "detectors": {
    "syncnet": {
      "score": 0.846,
      "offset_frames": 0,
      "confidence": 4.638,
      "min_dist": 6.627
    },
    "efficientnet": {
      "score": 0.68,
      "confidence": 0.82,
      "consistency": 0.91,
      "num_frames": 20
    }
  },
  "weights": {
    "syncnet": 0.4,
    "efficientnet": 0.6
  },
  "ensemble_mode": "full",
  "detectors_used": ["syncnet", "efficientnet"]
}
```

**‚úÖ Frontend NO requiere cambios** - Todos los campos esperados est√°n presentes.

---

## üö® Rollback Plan

Si algo falla, rollback inmediato:

```bash
cd /workspaces/demovozv3/syncnet-service

# 1. Restaurar requirements.txt
cp requirements.txt.backup requirements.txt
pip install -r requirements.txt

# 2. Restaurar .env
cp .env.backup .env

# 3. Restaurar app.py desde git
git checkout app.py

# 4. Eliminar carpeta ensemble
rm -rf ensemble/

# 5. Reiniciar servicio
pkill -f "python.*app.py"
python3 app.py

# Sistema vuelve al estado original (solo SyncNet)
```

---

## üìà M√©tricas de √âxito

| M√©trica | Antes (SyncNet) | Meta (Ensemble) |
|---------|-----------------|-----------------|
| Detecci√≥n deepfakes baja calidad | ~70% | >90% |
| Detecci√≥n deepfakes calidad media | ~30% ‚ùå | >75% ‚úÖ |
| Detecci√≥n deepfakes alta calidad | ~10% ‚ùå | >60% ‚úÖ |
| Falsos positivos (videos reales) | ~10% | <15% |
| Tiempo de procesamiento | ~7s | <15s |
| Compatibilidad API | 100% | 100% ‚úì |

---

## ‚úÖ Checklist de Implementaci√≥n

### Pre-implementaci√≥n
- [ ] Hacer backup completo del c√≥digo actual
- [ ] Crear branch git `feature/efficientnet-ensemble`
- [ ] Revisar espacio en disco para modelo (~20MB)
- [ ] Verificar Python 3.8+

### Implementaci√≥n
- [ ] Ejecutar FASE 1: Preparaci√≥n
  - [ ] Clonar repositorio EfficientNet
  - [ ] Instalar dependencias nuevas
  - [ ] Descargar modelo pre-entrenado
  - [ ] Actualizar .env
- [ ] Ejecutar FASE 2: M√≥dulos Nuevos
  - [ ] Crear `ensemble/efficientnet_detector.py`
  - [ ] Crear `ensemble/frame_extractor.py`
  - [ ] Crear `ensemble/orchestrator.py`
- [ ] Ejecutar FASE 3: Integraci√≥n Flask
  - [ ] Actualizar `app.py`
  - [ ] Verificar imports
- [ ] Ejecutar FASE 4: Testing
  - [ ] Test unitario EfficientNet
  - [ ] Test unitario Ensemble
  - [ ] Test end-to-end con video real
  - [ ] Test end-to-end con video deepfake

### Post-implementaci√≥n
- [ ] Verificar logs de servicio Python
- [ ] Test desde frontend (grabaci√≥n + carga manual)
- [ ] Verificar tiempo de procesamiento <15s
- [ ] Validar respuesta JSON compatible
- [ ] Monitorear primeras 24h

---

## üéì Conclusi√≥n

Este plan quir√∫rgico garantiza:

1. **‚úÖ Cero impacto en frontend** - Sin cambios en React
2. **‚úÖ Cambio m√≠nimo en backend** - Solo respuesta API extendida
3. **‚úÖ Integraci√≥n modular en Python** - Patr√≥n adaptador
4. **‚úÖ Retrocompatibilidad total** - API mantiene estructura
5. **‚úÖ Extensibilidad** - F√°cil agregar m√°s detectores
6. **‚úÖ Rollback r√°pido** - Restauraci√≥n en <5 minutos
7. **‚úÖ Mejora significativa** - +40% precisi√≥n esperada

**Pr√≥ximo paso:** Ejecutar FASE 1 cuando est√©s listo.

---

**Autor:** Claude + An√°lisis de Arquitectura
**Fecha:** 2025-11-03
**Versi√≥n:** 1.0
